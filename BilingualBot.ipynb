{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfeGowXPjcvU",
        "outputId": "5b719e0d-fc5d-466f-f534-18deff017c34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-cP0z1VjkVW",
        "outputId": "3b75e5f8-2d99-4cbe-f465-bfbe4b6af9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting newspaper3k\n",
            "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (8.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0)\n",
            "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.2)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.27.1)\n",
            "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tldextract>=2.0.1 (from newspaper3k)\n",
            "  Downloading tldextract-3.4.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting feedfinder2>=0.0.4 (from newspaper3k)\n",
            "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
            "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
            "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
            "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.12.0)\n",
            "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13541 sha256=7e6026fef78c61cf78ec5181d44314701b73f4334c63e4c4fcbb6d2a6f449a9f\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/d6/6c/384f58df48c00b9a31d638005143b5b3ac62c3d25fb1447f23\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=30bef78fb88a686eb64c4626cfd58f43fadaf53ca01fc6507d8ee5f086ef893d\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/02/e7/a1ff1760e12bdbaab0ac824fae5c1bc933e41c4ccd6a8f8edb\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=7035420e94cf8e40775b17be1a60c357850333629a316eb313e900ed6877f902\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/c4/0c/12a9a314ecac499456c4c3b2fcc2f635a3b45a39dfbd240299\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=8359a1a3ed6b483c7cd980504fec5606e55fd34e71158b99ad0415c712fc0d8b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/69/93/a47e9d621be168e9e33c7ce60524393c0b92ae83cf6c6e89c5\n",
            "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
            "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
            "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.10 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.4.4\n"
          ]
        }
      ],
      "source": [
        "pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F5q_uPu0kyF",
        "outputId": "62b7726c-5cc4-4b41-dded-219f5604789b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.34.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles (from gradio)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.97.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.6 (from gradio)\n",
            "  Downloading gradio_client-0.2.6-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gradio) (1.22.4)\n",
            "Collecting orjson (from gradio)\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio) (1.10.7)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.14.0)\n",
            "Collecting python-multipart (from gradio)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio) (2.27.1)\n",
            "Collecting semantic-version (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (2023.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (3.12.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio) (2022.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio)\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio) (1.26.15)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio) (1.16.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=18ca7079ccd12646b9ec842459704e9e09ea28467eca4b654680522b2700e352\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uc-micro-py, semantic-version, python-multipart, orjson, multidict, h11, frozenlist, async-timeout, aiofiles, yarl, uvicorn, starlette, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, aiosignal, httpx, fastapi, aiohttp, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 fastapi-0.97.0 ffmpy-0.3.0 frozenlist-1.3.3 gradio-3.34.0 gradio-client-0.2.6 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 multidict-6.0.4 orjson-3.9.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 starlette-0.27.0 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cicIaboNjneC"
      },
      "outputs": [],
      "source": [
        "from newspaper import Article\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import warnings\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgihl_LSjtQn"
      },
      "outputs": [],
      "source": [
        "#ignore the warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_nY9c3yjvHb",
        "outputId": "5074576c-4fe7-4c1a-bd5b-371b789c2692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#download package from nltk\n",
        "nltk.download('punkt',quiet=True)\n",
        "nltk.download('wordnet',quiet=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6YumKeopLRD"
      },
      "source": [
        "##Common Part (Common Tasks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvv0f32-j3Hb",
        "outputId": "c6fd09fb-bb96-42d1-a8f5-78e8fc2f43eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "{33: None, 34: None, 35: None, 36: None, 37: None, 38: None, 39: None, 40: None, 41: None, 42: None, 43: None, 44: None, 45: None, 46: None, 47: None, 58: None, 59: None, 60: None, 61: None, 62: None, 63: None, 64: None, 91: None, 92: None, 93: None, 94: None, 95: None, 96: None, 123: None, 124: None, 125: None, 126: None}\n"
          ]
        }
      ],
      "source": [
        "#creating a dictionary to remove the punctuation\n",
        "remove_punct_dict=dict( (ord(punct),None) for punct in string.punctuation)\n",
        "print(string.punctuation)\n",
        "print(remove_punct_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd-7NeqboZYE"
      },
      "source": [
        "##English Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0v2xm4djwmO"
      },
      "outputs": [],
      "source": [
        "#get artical url\n",
        "english_article = Article('https://en.wikipedia.org/wiki/Constitution_of_Lebanon')\n",
        "english_article .download()\n",
        "english_article .parse()\n",
        "english_article.nlp()\n",
        "english_corpus=english_article.text\n",
        "#print\n",
        "#print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtolgAEZsl0X",
        "outputId": "511b39af-a661-4728-da77-2956a663c9a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The Constitution of Lebanon was adopted on 23 May 1926.', 'Article 11, on the Official National Language, declares that \"Arabic is the official national language.', 'A law determines the cases in which the French language may be used.\"', \"The most recent amendment of the Constitution was for the Charter of Lebanese National Reconciliation (Ta'if Accord), in October, 1989.\", 'In an attempt to maintain equality between Christians and Muslims, Article 24 of the constitution mandates the distribution of offices on the basis of Confessionalism as an interim measure, but does not specify how they are to be allocated.', '(See National Pact.)', 'It does, nevertheless, specify that half the seats shall be given to Christians and half to Muslims.', 'Article 24 in its entirety reads as follows.', '[1]\\n\\nUntil such time as the Chamber enacts new electoral laws on a non-confessional basis, the distribution of seats shall be according to the following principles: Equal representation between Christians and Muslims.', 'Proportional representation among the confessional groups within each of the two religious communities.', 'Proportional representation among geographic regions.', 'Exceptionally, and for one time only, the seats that are currently vacant, as well as the new seats that have been established by law, shall be filled by appointment, all at once, and by a two thirds majority of the Government of National Unity.', 'This is to establish equality between Christians and Muslims as stipulated in the Document of National Accord.', 'The electoral laws shall specify the details regarding the implementation of this clause.', 'The constitution describes the flag of Lebanon.', 'The original version of Article 5 read \"The Lebanese flag is blue, white, red with a cedar in the white part\".', 'A change made on 7 December 1943 indicated that \"The Lebanese flag is made of red, white and red horizontal stripes, with the cedar in green in the centre of the white stripe\".', 'Some flag manufacturers have created a more conventional looking tree, with a brown trunk.', 'Some allege that this is unconstitutional.', '[2]\\n\\nA scholarly reference book on the Lebanese Constitution, describing its history and citing its full text as well as all its amendments was published in 1968 by Shafik Jiha and Wadih Chbat.', '[3]\\n\\nSee also [ edit ]\\n\\nReferences [ edit ]']\n"
          ]
        }
      ],
      "source": [
        "#tokenization\n",
        "english_text=english_corpus\n",
        "sent_tokensEN=nltk.sent_tokenize(english_text)\n",
        "print(sent_tokensEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJZfqFPsj5_Q",
        "outputId": "66b64940-40b3-4639-a076-fc9363b9eb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['the', 'constitution', 'of', 'lebanon', 'was', 'adopted', 'on', '23', 'may', '1926', 'article', '11', 'on', 'the', 'official', 'national', 'language', 'declares', 'that', 'arabic', 'is', 'the', 'official', 'national', 'language', 'a', 'law', 'determines', 'the', 'cases', 'in', 'which', 'the', 'french', 'language', 'may', 'be', 'used', 'the', 'most', 'recent', 'amendment', 'of', 'the', 'constitution', 'was', 'for', 'the', 'charter', 'of', 'lebanese', 'national', 'reconciliation', 'taif', 'accord', 'in', 'october', '1989', 'in', 'an', 'attempt', 'to', 'maintain', 'equality', 'between', 'christians', 'and', 'muslims', 'article', '24', 'of', 'the', 'constitution', 'mandates', 'the', 'distribution', 'of', 'offices', 'on', 'the', 'basis', 'of', 'confessionalism', 'as', 'an', 'interim', 'measure', 'but', 'does', 'not', 'specify', 'how', 'they', 'are', 'to', 'be', 'allocated', 'see', 'national', 'pact', 'it', 'does', 'nevertheless', 'specify', 'that', 'half', 'the', 'seats', 'shall', 'be', 'given', 'to', 'christians', 'and', 'half', 'to', 'muslims', 'article', '24', 'in', 'its', 'entirety', 'reads', 'as', 'follows1', 'until', 'such', 'time', 'as', 'the', 'chamber', 'enacts', 'new', 'electoral', 'laws', 'on', 'a', 'nonconfessional', 'basis', 'the', 'distribution', 'of', 'seats', 'shall', 'be', 'according', 'to', 'the', 'following', 'principles', 'equal', 'representation', 'between', 'christians', 'and', 'muslims', 'proportional', 'representation', 'among', 'the', 'confessional', 'groups', 'within', 'each', 'of', 'the', 'two', 'religious', 'communities', 'proportional', 'representation', 'among', 'geographic', 'regions', 'exceptionally', 'and', 'for', 'one', 'time', 'only', 'the', 'seats', 'that', 'are', 'currently', 'vacant', 'as', 'well', 'as', 'the', 'new', 'seats', 'that', 'have', 'been', 'established', 'by', 'law', 'shall', 'be', 'filled', 'by', 'appointment', 'all', 'at', 'once', 'and', 'by', 'a', 'two', 'thirds', 'majority', 'of', 'the', 'government', 'of', 'national', 'unity', 'this', 'is', 'to', 'establish', 'equality', 'between', 'christians', 'and', 'muslims', 'as', 'stipulated', 'in', 'the', 'document', 'of', 'national', 'accord', 'the', 'electoral', 'laws', 'shall', 'specify', 'the', 'details', 'regarding', 'the', 'implementation', 'of', 'this', 'clause', 'the', 'constitution', 'describes', 'the', 'flag', 'of', 'lebanon', 'the', 'original', 'version', 'of', 'article', '5', 'read', 'the', 'lebanese', 'flag', 'is', 'blue', 'white', 'red', 'with', 'a', 'cedar', 'in', 'the', 'white', 'part', 'a', 'change', 'made', 'on', '7', 'december', '1943', 'indicated', 'that', 'the', 'lebanese', 'flag', 'is', 'made', 'of', 'red', 'white', 'and', 'red', 'horizontal', 'stripes', 'with', 'the', 'cedar', 'in', 'green', 'in', 'the', 'centre', 'of', 'the', 'white', 'stripe', 'some', 'flag', 'manufacturers', 'have', 'created', 'a', 'more', 'conventional', 'looking', 'tree', 'with', 'a', 'brown', 'trunk', 'some', 'allege', 'that', 'this', 'is', 'unconstitutional2', 'a', 'scholarly', 'reference', 'book', 'on', 'the', 'lebanese', 'constitution', 'describing', 'its', 'history', 'and', 'citing', 'its', 'full', 'text', 'as', 'well', 'as', 'all', 'its', 'amendments', 'was', 'published', 'in', '1968', 'by', 'shafik', 'jiha', 'and', 'wadih', 'chbat3', 'see', 'also', 'edit', 'references', 'edit']\n"
          ]
        }
      ],
      "source": [
        "#create a function to return lower case words \n",
        "def LemNormalize(text):\n",
        "  return nltk.word_tokenize(text.lower().translate(remove_punct_dict))\n",
        "print(LemNormalize(english_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_y-nRPIj82h"
      },
      "outputs": [],
      "source": [
        "#keywords for greetings\n",
        "english_greeting_input=[\"hi\",\"hello\",\"hey\",\"hola\"]\n",
        "english_greeting_response=[\"howdy\",\"hey there\",\"hi\",\"hello :)\"]\n",
        "def english_greeting(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in english_greeting_input:\n",
        "      return random.choice(english_greeting_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6q8KOrw6kANR"
      },
      "outputs": [],
      "source": [
        "def english_response(user_response):\n",
        " #user response and robo responce\n",
        "  #user_response=\"WHat is chronic disease\"\n",
        "  user_response=user_response.lower()\n",
        "  #print(user_response)\n",
        "  #robo response\n",
        "  robo_response=''\n",
        "  sent_tokensEN.append(user_response)\n",
        "  #print(sent_tokens)\n",
        "  tfidfvec=TfidfVectorizer(tokenizer=LemNormalize , stop_words='english')\n",
        "  tfidf=tfidfvec.fit_transform(sent_tokensEN)\n",
        "  #print(tfidf)\n",
        "  #get similarity score\n",
        "  val=cosine_similarity(tfidf[-1],tfidf)\n",
        "  #print(val)\n",
        "  idx=val.argsort()[0][-2]\n",
        "  flat=val.flatten()\n",
        "  flat.sort()\n",
        "  score=flat[-2]\n",
        "  #print(score)\n",
        "  if score==0:\n",
        "    robo_response=robo_response+\"sorry,i dont understand\"\n",
        "  else:\n",
        "    robo_response=robo_response+sent_tokensEN[idx]\n",
        "\n",
        "  sent_tokensEN.remove(user_response)\n",
        "  return robo_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KiH1PpvoUea"
      },
      "source": [
        "##Arabic Part"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KW_YDFzUps0d"
      },
      "outputs": [],
      "source": [
        "#get artical url\n",
        "arabic_article= Article('https://ar.wikipedia.org/wiki/دستور_لبنان')\n",
        "# Set the language to Arabic\n",
        "arabic_article.language = 'ar'\n",
        "arabic_article.download()\n",
        "arabic_article.parse()\n",
        "arabic_article.nlp()\n",
        "arabic_corpus=arabic_article.text\n",
        "#print\n",
        "#print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lnseTvmjzwu",
        "outputId": "5918b0f0-e55e-4d6e-d604-55c92008f938"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['دستور لبنان، هو القانون الأعلى الذي يحدد شكل الدولة في لبنان.', 'صدر في 23 أيار / مايو 1926 وذلك أثناء فترة الانتداب الفرنسي وذلك بعد إقراره من مجلس الممثلين[1]، وتم بإقرار الدستور الإعلان عن قيام الجمهورية اللبنانية بعد أن كانت تسمى منذ بدء الانتداب بدولة لبنان الكبير.', 'مكونات الدستور [ عدل ]\\n\\nيتكون الدستور اللبناني من سته أبواب، ويقسم الباب الأول إلى فصلين بالإضافة إلى مقدمة، بينما يقسم الباب الثاني إلى أربعة فصول.', 'وقد عُدِّل الدستور بعد التوقيع على اتفاق الطائف بعام 1989 والذي وضع حدّاً للحرب الأهلية اللبنانية[2]، ومن أهم التعديلات التي أُدخلت عليه المناصفة بين الديانتين الإسلامية والمسيحية بعد أن كان هناك تمييز للمسيحيين.', 'المراجع [ عدل ]']\n"
          ]
        }
      ],
      "source": [
        "#tokenization\n",
        "arabic_text=arabic_corpus\n",
        "sent_tokensAR=nltk.sent_tokenize(arabic_text)\n",
        "print(sent_tokensAR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSutKLACp0T1",
        "outputId": "bd764b9e-4cc3-4f26-b306-61d774d3d9a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['دستور', 'لبنان،', 'هو', 'القانون', 'الأعلى', 'الذي', 'يحدد', 'شكل', 'الدولة', 'في', 'لبنان', '.', 'صدر', 'في', '23', 'أيار', '/', 'مايو', '1926', 'وذلك', 'أثناء', 'فترة', 'الانتداب', 'الفرنسي', 'وذلك', 'بعد', 'إقراره', 'من', 'مجلس', 'الممثلين', '[', '1', ']', '،', 'وتم', 'بإقرار', 'الدستور', 'الإعلان', 'عن', 'قيام', 'الجمهورية', 'اللبنانية', 'بعد', 'أن', 'كانت', 'تسمى', 'منذ', 'بدء', 'الانتداب', 'بدولة', 'لبنان', 'الكبير', '.', 'مكونات', 'الدستور', '[', 'عدل', ']', 'يتكون', 'الدستور', 'اللبناني', 'من', 'سته', 'أبواب،', 'ويقسم', 'الباب', 'الأول', 'إلى', 'فصلين', 'بالإضافة', 'إلى', 'مقدمة،', 'بينما', 'يقسم', 'الباب', 'الثاني', 'إلى', 'أربعة', 'فصول', '.', 'وقد', 'عُدِّل', 'الدستور', 'بعد', 'التوقيع', 'على', 'اتفاق', 'الطائف', 'بعام', '1989', 'والذي', 'وضع', 'حدّاً', 'للحرب', 'الأهلية', 'اللبنانية', '[', '2', ']', '،', 'ومن', 'أهم', 'التعديلات', 'التي', 'أُدخلت', 'عليه', 'المناصفة', 'بين', 'الديانتين', 'الإسلامية', 'والمسيحية', 'بعد', 'أن', 'كان', 'هناك', 'تمييز', 'للمسيحيين', '.', 'المراجع', '[', 'عدل', ']']\n"
          ]
        }
      ],
      "source": [
        "def arabic_tokenizer(text):\n",
        "    # Tokenize Arabic text using nltk's word_tokenize function\n",
        "    return nltk.word_tokenize(text)\n",
        "print(arabic_tokenizer(arabic_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejls2Buop5c2"
      },
      "outputs": [],
      "source": [
        "#keywords for greetings\n",
        "arabic_greeting_input =[\"مرحبا\",\"أهلا\"]\n",
        "arabic_greeting_response=[\"مرحبا بكم\"]\n",
        "def arabic_greeting(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in arabic_greeting_input:\n",
        "      return random.choice(arabic_greeting_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Y_IXXurCjX"
      },
      "outputs": [],
      "source": [
        "arabic_stopwords = [\n",
        "    'في', 'من', 'عن', 'إلى', 'على', 'هذا', 'هذه', 'هم', 'هناك', 'هي', 'هو',\n",
        "    'أنت', 'أنا', 'نحن', 'إذا', 'عند', 'على', 'عليه', 'عليها', 'عليهم',\n",
        "    'عليهن', 'علينا', 'أنا', 'أنت', 'أنتم', 'أنتن', 'إياك', 'إياه', 'إياها',\n",
        "    'إياهم', 'إياهن', 'إياهما', 'إيانا', 'أنتما', 'إيانك', 'أنتن', 'هي', 'هو'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZJpfwZ5rLyH"
      },
      "outputs": [],
      "source": [
        "def arabic_response(user_response):\n",
        " #user response and robo responce\n",
        "  #user_response=\"WHat is chronic disease\"\n",
        "  user_response=user_response.lower()\n",
        "  #print(user_response)\n",
        "  #robo response\n",
        "  robo_response=''\n",
        "  sent_tokensAR.append(user_response)\n",
        "  #print(sent_tokens)\n",
        "  tfidfvec=TfidfVectorizer(tokenizer=arabic_tokenizer , stop_words=arabic_stopwords)\n",
        "  tfidf=tfidfvec.fit_transform(sent_tokensAR)\n",
        "  #print(tfidf)\n",
        "  #get similarity score\n",
        "  val=cosine_similarity(tfidf[-1],tfidf)\n",
        "  #print(val)\n",
        "  idx=val.argsort()[0][-2]\n",
        "  flat=val.flatten()\n",
        "  flat.sort()\n",
        "  score=flat[-2]\n",
        "  #print(score)\n",
        "  if score==0:\n",
        "    robo_response=robo_response+\"أعتذر ليس لدي معلومات حول هذا الموضوع\"\n",
        "  else:\n",
        "    robo_response=robo_response+sent_tokensAR[idx]\n",
        "\n",
        "  sent_tokensAR.remove(user_response)\n",
        "  return robo_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_I9IqphouNxi"
      },
      "source": [
        "##Bilingual Bot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwNfQ8eqoOlX",
        "outputId": "0416184f-8a85-41f0-f633-04a43d325ccc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Language selection:\n",
            "1. English\n",
            "2. Arabic\n",
            "مرحبا! أنا المتحدث الآلي فيفي. أستطيع أن أجيب على أسئلتك المتعلقة بالدستور اللبناني. قم بكتابة 'شكرا' لإنهاء المحادثة.\n",
            "Vivy: دستور لبنان، هو القانون الأعلى الذي يحدد شكل الدولة في لبنان.\n",
            "Vivy: مكونات الدستور [ عدل ]\n",
            "\n",
            "يتكون الدستور اللبناني من سته أبواب، ويقسم الباب الأول إلى فصلين بالإضافة إلى مقدمة، بينما يقسم الباب الثاني إلى أربعة فصول.\n",
            "Vivy: أعتذر ليس لدي معلومات حول هذا الموضوع\n"
          ]
        }
      ],
      "source": [
        "flag = True\n",
        "print(\"Language selection:\")\n",
        "print(\"1. English\")\n",
        "print(\"2. Arabic\")\n",
        "\n",
        "language_choice = input(\"Select your preferred language. اختر لغتك المفضلة (1/ 2): \")\n",
        "\n",
        "if language_choice == '1':\n",
        "    print(\"Hello! This is Vivy. I can answer your queries related to light. Type 'bye' to exit.\")\n",
        "\n",
        "elif language_choice == '2':\n",
        "    print(\"مرحبا! أنا المتحدث الآلي فيفي. أستطيع أن أجيب على أسئلتك المتعلقة بالدستور اللبناني. قم بكتابة 'شكرا' لإنهاء المحادثة.\")\n",
        "\n",
        "else:\n",
        "    print(\"Invalid language choice.\")\n",
        "\n",
        "while flag:\n",
        "    user_response = input(\"You: \")\n",
        "\n",
        "    if user_response != 'bye':\n",
        "        if language_choice == '1':\n",
        "            if user_response == 'thanks' or user_response == 'thank you':\n",
        "                flag = False\n",
        "                print(\"Vivy: You're welcome :)\")\n",
        "\n",
        "            else:\n",
        "                greeting = english_greeting(user_response)\n",
        "                if greeting is not None:\n",
        "                    print(\"Vivy: \" + greeting)\n",
        "                else:\n",
        "                    print(\"Vivy: \" + english_response(user_response))\n",
        "\n",
        "        elif language_choice == '2':\n",
        "            if user_response == 'شكرا' or user_response == 'شكرا لك':\n",
        "                flag = False\n",
        "                print(\"Vivy: على الرحب والسعة\")\n",
        "\n",
        "            else:\n",
        "                greeting = arabic_greeting(user_response)\n",
        "                if greeting is not None:\n",
        "                    print(\"Vivy: \" + greeting)\n",
        "                else:\n",
        "                    print(\"Vivy: \" + arabic_response(user_response))\n",
        "\n",
        "        else:\n",
        "            print(\"Vivy: Invalid language choice.\")\n",
        "\n",
        "    else:\n",
        "        flag = False\n",
        "        if language_choice == '1':\n",
        "            print(\"Vivy: See you later :)\")\n",
        "        elif language_choice == '2':\n",
        "            print(\"Vivy: إلى اللقاء\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CizXYa0P2a_h"
      },
      "outputs": [],
      "source": [
        "def chatbot_interaction(user_response, language_choice):\n",
        "    if language_choice == '1':\n",
        "        if user_response == 'thanks' or user_response == 'thank you':\n",
        "            return \"Vivy: You're welcome :)\"\n",
        "        else:\n",
        "            greeting = english_greeting(user_response)\n",
        "            if greeting is not None:\n",
        "                return \"Vivy: \" + greeting\n",
        "            else:\n",
        "                return \"Vivy: \" + english_response(user_response)\n",
        "    elif language_choice == '2':\n",
        "        if user_response == 'شكرا' or user_response == 'شكرا لك':\n",
        "            return \"Vivy: على الرحب والسعة\"\n",
        "        else:\n",
        "            greeting = arabic_greeting(user_response)\n",
        "            if greeting is not None:\n",
        "                return \"Vivy: \" + greeting\n",
        "            else:\n",
        "                return \"Vivy: \" + arabic_response(user_response)\n",
        "    else:\n",
        "        return \"Vivy: Invalid language choice.\"\n",
        "\n",
        "language_input = gr.inputs.Textbox(label=\"Select your preferred language (1 for English, 2 for Arabic):\")\n",
        "chat_input = gr.inputs.Textbox(label=\"You\")\n",
        "chat_output = gr.outputs.Textbox(label=\"Vivy\")\n",
        "\n",
        "def chatbot_interface(language_input, user_input):\n",
        "    language_choice = language_input.strip()\n",
        "    if language_choice == '1':\n",
        "        intro_message = \"Hello! This is Vivy. I can answer your queries related to light. Type 'bye' to exit.\"\n",
        "    elif language_choice == '2':\n",
        "        intro_message = \"مرحبا! أنا المتحدث الآلي فيفي. أستطيع أن أجيب على أسئلتك المتعلقة بالدستور اللبناني. قم بكتابة 'شكرا' لإنهاء المحادثة.\"\n",
        "    else:\n",
        "        intro_message = \"Invalid language choice.\"\n",
        "\n",
        "    if intro_message != \"Invalid language choice.\":\n",
        "        return intro_message + \"\\n\" + chatbot_interaction(user_input, language_choice)\n",
        "    else:\n",
        "        return intro_message\n",
        "\n",
        "chat_interface = gr.Interface(\n",
        "    fn=chatbot_interface,\n",
        "    inputs=[language_input, chat_input],\n",
        "    outputs=chat_output,\n",
        "    title=\"Chatbot\",\n",
        "    description=\"Enter your preferred language and start the conversation with the chatbot.\"\n",
        ")\n",
        "\n",
        "chat_interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rg38j66lwOo2"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}